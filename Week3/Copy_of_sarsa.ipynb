{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sarsa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRnyIWj_yg49"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvmtoQ9_yg5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69db464-7b33-4468-9f1f-f86a5f6cc168"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73qgl7RLyg5D"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35WhRGfcyg5H"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p54c_Hhyg5I"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "          return 0.0\n",
        "        else:\n",
        "          value = np.max([self.get_qvalue(state, a) for a in possible_actions])\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        new_q_value = (1 - learning_rate) * self.get_qvalue(state, action) + learning_rate * (reward + gamma * self.get_value(next_state))\n",
        "\n",
        "        self.set_qvalue(state, action, new_q_value)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        best_action = np.argmax([self.get_qvalue(state, a) for a in possible_actions])\n",
        "\n",
        "        return possible_actions[best_action]\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.getPolicy).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = self.get_best_action(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "          chosen_action = random.choice(possible_actions)\n",
        "        else:\n",
        "          chosen_action = action\n",
        "  \n",
        "        return chosen_action"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDXzAbXvyg5K"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ExkuVwyg5L"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        \n",
        "        #a policy π is a probability distribution over actions given states. That is the likelihood of every action when an agent is in a particular state \n",
        "        \n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "        \n",
        "        #sum of probability of action times q value of actions in that state\n",
        "        #likelihood of a single NOT OPTIMAL action, probability of action (in this case: 4 possible actions therefore 1/4 for each action) * epsilon.\n",
        "        #likelihood of OPTIMAL action, (probability of action (in this case: 4 possible actions therefore 1/4 for each action) * epsilon) + (1 - epsilon).\n",
        "        state_value = 0\n",
        "        for a in possible_actions:\n",
        "            if a == self.get_best_action(state):\n",
        "                state_value += ((1 - epsilon) + epsilon/len(possible_actions)) * self.get_qvalue(state,a)\n",
        "            else:\n",
        "                state_value += (epsilon/len(possible_actions)) * self.get_qvalue(state,a)\n",
        "\n",
        "        return state_value"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFpThgUJyg5N"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8au3i9HQyg5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3e0d1b-6b08-4861-a950-a4f6d3015d30"
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sc2IS0gyg5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938b146e-89b6-4387-e95c-2296c8fc1d83"
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDp6Nsytyg5P"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeKcD7xvyg5Q"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZIZjIMTyg5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "79408d5b-5070-4080-e099-698ccadaa55c"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVSARSA mean reward = -26.04\n",
            "QLEARNING mean reward = -74.44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt8tX4zOyg5Q"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arl6NYsTyg5R"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5gr_3Ogyg5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9094e4aa-9a4e-42b3-c260-c626955a3482"
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-Learning\n",
            " >  >  >  v  >  >  v  v  >  v  v  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUEe7enNyg5S"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}